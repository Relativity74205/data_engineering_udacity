{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Wrangling with DataFrames Coding Quiz\n",
    "\n",
    "Use this Jupyter notebook to find the answers to the quiz in the previous section. There is an answer key in the next part of the lesson."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/08/21 17:58:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"MySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "user_log.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\" (empty string) NOT visit?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# TODO: write your code to answer question 1\n",
    "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "visited_pages = user_log.where(user_log.userId == \"\").select(\"page\").dropDuplicates()\n",
    "all_pages = user_log.select(\"page\").dropDuplicates()\n",
    "set(all_pages.collect()) - set(visited_pages.collect())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{Row(page='Downgrade'),\n",
       " Row(page='Error'),\n",
       " Row(page='Logout'),\n",
       " Row(page='NextSong'),\n",
       " Row(page='Save Settings'),\n",
       " Row(page='Settings'),\n",
       " Row(page='Submit Downgrade'),\n",
       " Row(page='Submit Upgrade'),\n",
       " Row(page='Upgrade')}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "What type of user does the empty string user id most likely refer to?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# TODO: use this space to explore the behavior of the user with an empty string\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# TODO: write your code to answer question 3\n",
    "# user_log.select(\"gender\").drop_duplicates().show()\n",
    "\n",
    "user_log.select([\"userId\", \"gender\"]).drop_duplicates().groupBy(\"gender\").count().show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     F|  462|\n",
      "|  null|    1|\n",
      "|     M|  501|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# TODO: write your code to answer question 4\n",
    "\n",
    "user_log.filter(user_log.page == 'NextSong').groupBy(\"artist\").count().sort(\"count\", ascending=False).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-----+\n",
      "|              artist|count|\n",
      "+--------------------+-----+\n",
      "|            Coldplay|   83|\n",
      "|       Kings Of Leon|   69|\n",
      "|Florence + The Ma...|   52|\n",
      "|            BjÃÂ¶rk|   46|\n",
      "|       Dwight Yoakam|   45|\n",
      "|       Justin Bieber|   43|\n",
      "|      The Black Keys|   40|\n",
      "|         OneRepublic|   37|\n",
      "|                Muse|   36|\n",
      "|        Jack Johnson|   36|\n",
      "|           Radiohead|   31|\n",
      "|        Taylor Swift|   29|\n",
      "|Barry Tuckwell/Ac...|   28|\n",
      "|          Lily Allen|   28|\n",
      "|               Train|   28|\n",
      "|           Metallica|   27|\n",
      "|           Daft Punk|   27|\n",
      "|          Nickelback|   27|\n",
      "|          Kanye West|   26|\n",
      "|Red Hot Chili Pep...|   24|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# TODO: write your code to answer question 5\n",
    "\n",
    "user_log.filter(user_log.page == 'NextSong').groupBy([\"userId\", \"sessionId\"]).count().agg({'count':'avg'}).show()\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "function = udf(lambda ishome : int(ishome == 'Home'), IntegerType())\n",
    "\n",
    "user_window = Window \\\n",
    "    .partitionBy('userID') \\\n",
    "    .orderBy(desc('ts')) \\\n",
    "    .rangeBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "cusum = user_log.filter((user_log.page == 'NextSong') | (user_log.page == 'Home')) \\\n",
    "    .select('userID', 'page', 'ts') \\\n",
    "    .withColumn('homevisit', function(col('page'))) \\\n",
    "    .withColumn('period', Fsum('homevisit').over(user_window))\n",
    "\n",
    "cusum.filter((cusum.page == 'NextSong')) \\\n",
    "    .groupBy('userID', 'period') \\\n",
    "    .agg({'period':'count'}) \\\n",
    "    .agg({'count(period)':'avg'}).show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "349d298007a5c87f450f5892f73dda0e195efb5114222f7bc6e208c47c336c0a"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}